{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "\n",
    "import contractions\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import swifter\n",
    "import torch\n",
    "import unidecode\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Ted Talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/python-sentiment-analysis-using-vader/\n",
    "# function to print sentiments of the sentences.\n",
    "def sentiment_scores(sentence):\n",
    "    # create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # polarity_scores method of SentimentIntensityAnalyzer\n",
    "    # oject gives a sentiment dictionary.\n",
    "    # which contains pos, neg, neu, and compound scores.\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "\n",
    "    print(\"Overall sentiment dictionary is : \", sentiment_dict)\n",
    "    print(\"sentence was rated as \", sentiment_dict['neg'] * 100, \"% Negative\")\n",
    "    print(\"sentence was rated as \", sentiment_dict['neu'] * 100, \"% Neutral\")\n",
    "    print(\"sentence was rated as \", sentiment_dict['pos'] * 100, \"% Positive\")\n",
    "\n",
    "    print(\"Sentence Overall Rated As\", end=\" \")\n",
    "    # decide sentiment as positive, negative and neutral\n",
    "    if sentiment_dict['compound'] >= 0.05:\n",
    "        print(\"Positive\")\n",
    "    elif sentiment_dict['compound'] <= -0.05:\n",
    "        print(\"Negative\")\n",
    "    else:\n",
    "        print(\"Neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_main = pd.read_csv('data/ted_main.csv')\n",
    "transcripts = pd.read_csv('data/transcripts.csv')\n",
    "ted_merged = pd.merge(left=transcripts, right=ted_main, left_on='url', right_on='url')\n",
    "transcript = ted_merged.transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_num(input_str):\n",
    "    return re.sub(r'\\d+', '', input_str)\n",
    "def remove_string_between_paran(x):\n",
    "    return re.sub(\"([\\(\\[]).*?([\\)\\]])\", \"\\g<1> \\g<2>\", x)\n",
    "transcript = transcript.apply(contractions.fix) # remove contractions\n",
    "transcript = transcript.str.lower() # lowercase\n",
    "transcript = transcript.apply(rm_num) # remove numbers\n",
    "# specials = '()'\n",
    "# transcript = transcript.str.translate(str.maketrans('()',' '*len(specials))) # remove par around laughter\n",
    "transcript = transcript.apply(remove_string_between_paran)\n",
    "# transcript = transcript.str.translate(str.maketrans('','',string.punctuation)) # remove punctuation\n",
    "transscipt = transcript.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # setiment analysis\n",
    "# transscipt.swifter.apply(sentiment_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemma = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "clean_transcript = {}\n",
    "for i, transcript_one in enumerate(transcript):\n",
    "#     clean_transcript[i] = ' '.join(lemma.lemmatize(word) for word in word_tokenize(transcript_one) if  word not in stop_words)\n",
    "    clean_transcript[i] = transcript_one.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU!\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = clean_transcript[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['good', 'morning.'], 'how'), (['morning.', 'how'], 'are'), (['how', 'are'], 'you?(')]\n"
     ]
    }
   ],
   "source": [
    "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "            for i in range(len(test_sentence) - 2)]\n",
    "chunk_len=len(trigrams)\n",
    "print(trigrams[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(test_sentence)\n",
    "voc_len=len(vocab)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp=[]\n",
    "tar=[]\n",
    "for context, target in trigrams:\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        inp.append(context_idxs)\n",
    "        targ = torch.tensor([word_to_ix[target]], dtype=torch.long)\n",
    "        tar.append(targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size*2, hidden_size, n_layers,batch_first=True,\n",
    "                          bidirectional=False)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden().cuda()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[c].cuda(), hidden)\n",
    "        loss += criterion(output, target[c].cuda())\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data.item() / chunk_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 100\n",
    "n_layers = 1\n",
    "lr = 0.015\n",
    "\n",
    "decoder = RNN(voc_len, hidden_size, voc_len, n_layers)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "if(train_on_gpu):\n",
    "    decoder.to('cuda:0')\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(inp,tar)       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 50, loss))\n",
    "#         print(evaluate('ge', 200), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7e700a2d50>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prime_str='good morning', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden().cuda()\n",
    "\n",
    "    for p in range(predict_len):\n",
    "        \n",
    "        prime_input = torch.tensor([word_to_ix[w] for w in prime_str.split()], dtype=torch.long).cuda()\n",
    "        inp = prime_input[-2:] #last two words as input\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted word to string and use as next input\n",
    "        predicted_word = list(word_to_ix.keys())[list(word_to_ix.values()).index(top_i)]\n",
    "        prime_str += \" \" + predicted_word\n",
    "#         inp = torch.tensor(word_to_ix[predicted_word], dtype=torch.long)\n",
    "\n",
    "    return prime_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'morning'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a9049d8e3579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'good morning'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-0eb1c0d3a3fd>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(prime_str, predict_len, temperature)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mprime_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_to_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprime_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprime_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#last two words as input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-0eb1c0d3a3fd>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mprime_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_to_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprime_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprime_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#last two words as input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'morning'"
     ]
    }
   ],
   "source": [
    "print(evaluate('good morning', 40, temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluate('whole thing', 30, temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # word2vec\n",
    "# path = get_tmpfile(\"word2vec.model\")\n",
    "# model = Word2Vec(common_texts,\n",
    "#                  size=256,\n",
    "#                  window=5,\n",
    "#                  min_count=1,\n",
    "#                  workers=16,\n",
    "#                  sg=1)\n",
    "# model.save(\"word2vec.model\")\n",
    "# # # conti training\n",
    "# # model = Word2Vec.load(\"word2vec.model\")\n",
    "# # model.train([[\"hello\", \"world\"]], total_examples=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model = Word2Vec(common_texts, size=100, window=5, min_count=1, workers=4)\n",
    "# model = KeyedVectors.load_word2vec_format('~/weight/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "# # model.wv['computer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "590px",
    "left": "27px",
    "right": "20px",
    "top": "211px",
    "width": "336px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import contractions\n",
    "import gensim\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/python-sentiment-analysis-using-vader/\n",
    "# import SentimentIntensityAnalyzer class \n",
    "# from vaderSentiment.vaderSentiment module. \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "  \n",
    "# function to print sentiments \n",
    "# of the sentence. \n",
    "def sentiment_scores(sentence): \n",
    "    # Create a SentimentIntensityAnalyzer object. \n",
    "    sid_obj = SentimentIntensityAnalyzer() \n",
    "    \n",
    "    # polarity_scores method of SentimentIntensityAnalyzer \n",
    "    # oject gives a sentiment dictionary. \n",
    "    # which contains pos, neg, neu, and compound scores. \n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence) \n",
    "      \n",
    "    print(\"Overall sentiment dictionary is : \", sentiment_dict) \n",
    "    print(\"sentence was rated as \", sentiment_dict['neg']*100, \"% Negative\") \n",
    "    print(\"sentence was rated as \", sentiment_dict['neu']*100, \"% Neutral\") \n",
    "    print(\"sentence was rated as \", sentiment_dict['pos']*100, \"% Positive\") \n",
    "    \n",
    "    print(\"Sentence Overall Rated As\", end = \" \") \n",
    "    # decide sentiment as positive, negative and neutral \n",
    "    if sentiment_dict['compound'] >= 0.05 : \n",
    "        print(\"Positive\") \n",
    "    elif sentiment_dict['compound'] <= - 0.05 : \n",
    "        print(\"Negative\") \n",
    "    else : \n",
    "        print(\"Neutral\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec\n",
    "path = get_tmpfile(\"word2vec.model\")\n",
    "model = Word2Vec(common_texts,\n",
    "                 size=256,\n",
    "                 window=5,\n",
    "                 min_count=1,\n",
    "                 workers=16,\n",
    "                 sg=1)\n",
    "model.save(\"word2vec.model\")\n",
    "# # conti training\n",
    "# model = Word2Vec.load(\"word2vec.model\")\n",
    "# model.train([[\"hello\", \"world\"]], total_examples=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_main = pd.read_csv('data/ted_main.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "      <th>film_date</th>\n",
       "      <th>languages</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>name</th>\n",
       "      <th>num_speaker</th>\n",
       "      <th>published_date</th>\n",
       "      <th>ratings</th>\n",
       "      <th>related_talks</th>\n",
       "      <th>speaker_occupation</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4553</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>1164</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140825600</td>\n",
       "      <td>60</td>\n",
       "      <td>Ken Robinson</td>\n",
       "      <td>Ken Robinson: Do schools kill creativity?</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>[{'id': 7, 'name': 'Funny', 'count': 19645}, {...</td>\n",
       "      <td>[{'id': 865, 'hero': 'https://pe.tedcdn.com/im...</td>\n",
       "      <td>Author/educator</td>\n",
       "      <td>['children', 'creativity', 'culture', 'dance',...</td>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>https://www.ted.com/talks/ken_robinson_says_sc...</td>\n",
       "      <td>47227110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>265</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>977</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140825600</td>\n",
       "      <td>43</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Al Gore: Averting the climate crisis</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>[{'id': 7, 'name': 'Funny', 'count': 544}, {'i...</td>\n",
       "      <td>[{'id': 243, 'hero': 'https://pe.tedcdn.com/im...</td>\n",
       "      <td>Climate advocate</td>\n",
       "      <td>['alternative energy', 'cars', 'climate change...</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>https://www.ted.com/talks/al_gore_on_averting_...</td>\n",
       "      <td>3200520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>New York Times columnist David Pogue takes aim...</td>\n",
       "      <td>1286</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140739200</td>\n",
       "      <td>26</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>David Pogue: Simplicity sells</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>[{'id': 7, 'name': 'Funny', 'count': 964}, {'i...</td>\n",
       "      <td>[{'id': 1725, 'hero': 'https://pe.tedcdn.com/i...</td>\n",
       "      <td>Technology columnist</td>\n",
       "      <td>['computers', 'entertainment', 'interface desi...</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>https://www.ted.com/talks/david_pogue_says_sim...</td>\n",
       "      <td>1636292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>In an emotionally charged talk, MacArthur-winn...</td>\n",
       "      <td>1116</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140912000</td>\n",
       "      <td>35</td>\n",
       "      <td>Majora Carter</td>\n",
       "      <td>Majora Carter: Greening the ghetto</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>[{'id': 3, 'name': 'Courageous', 'count': 760}...</td>\n",
       "      <td>[{'id': 1041, 'hero': 'https://pe.tedcdn.com/i...</td>\n",
       "      <td>Activist for environmental justice</td>\n",
       "      <td>['MacArthur grant', 'activism', 'business', 'c...</td>\n",
       "      <td>Greening the ghetto</td>\n",
       "      <td>https://www.ted.com/talks/majora_carter_s_tale...</td>\n",
       "      <td>1697550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>You've never seen data presented like this. Wi...</td>\n",
       "      <td>1190</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140566400</td>\n",
       "      <td>48</td>\n",
       "      <td>Hans Rosling</td>\n",
       "      <td>Hans Rosling: The best stats you've ever seen</td>\n",
       "      <td>1</td>\n",
       "      <td>1151440680</td>\n",
       "      <td>[{'id': 9, 'name': 'Ingenious', 'count': 3202}...</td>\n",
       "      <td>[{'id': 2056, 'hero': 'https://pe.tedcdn.com/i...</td>\n",
       "      <td>Global health expert; data visionary</td>\n",
       "      <td>['Africa', 'Asia', 'Google', 'demo', 'economic...</td>\n",
       "      <td>The best stats you've ever seen</td>\n",
       "      <td>https://www.ted.com/talks/hans_rosling_shows_t...</td>\n",
       "      <td>12005869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comments                                        description  duration  \\\n",
       "0      4553  Sir Ken Robinson makes an entertaining and pro...      1164   \n",
       "1       265  With the same humor and humanity he exuded in ...       977   \n",
       "2       124  New York Times columnist David Pogue takes aim...      1286   \n",
       "3       200  In an emotionally charged talk, MacArthur-winn...      1116   \n",
       "4       593  You've never seen data presented like this. Wi...      1190   \n",
       "\n",
       "     event   film_date  languages   main_speaker  \\\n",
       "0  TED2006  1140825600         60   Ken Robinson   \n",
       "1  TED2006  1140825600         43        Al Gore   \n",
       "2  TED2006  1140739200         26    David Pogue   \n",
       "3  TED2006  1140912000         35  Majora Carter   \n",
       "4  TED2006  1140566400         48   Hans Rosling   \n",
       "\n",
       "                                            name  num_speaker  published_date  \\\n",
       "0      Ken Robinson: Do schools kill creativity?            1      1151367060   \n",
       "1           Al Gore: Averting the climate crisis            1      1151367060   \n",
       "2                  David Pogue: Simplicity sells            1      1151367060   \n",
       "3             Majora Carter: Greening the ghetto            1      1151367060   \n",
       "4  Hans Rosling: The best stats you've ever seen            1      1151440680   \n",
       "\n",
       "                                             ratings  \\\n",
       "0  [{'id': 7, 'name': 'Funny', 'count': 19645}, {...   \n",
       "1  [{'id': 7, 'name': 'Funny', 'count': 544}, {'i...   \n",
       "2  [{'id': 7, 'name': 'Funny', 'count': 964}, {'i...   \n",
       "3  [{'id': 3, 'name': 'Courageous', 'count': 760}...   \n",
       "4  [{'id': 9, 'name': 'Ingenious', 'count': 3202}...   \n",
       "\n",
       "                                       related_talks  \\\n",
       "0  [{'id': 865, 'hero': 'https://pe.tedcdn.com/im...   \n",
       "1  [{'id': 243, 'hero': 'https://pe.tedcdn.com/im...   \n",
       "2  [{'id': 1725, 'hero': 'https://pe.tedcdn.com/i...   \n",
       "3  [{'id': 1041, 'hero': 'https://pe.tedcdn.com/i...   \n",
       "4  [{'id': 2056, 'hero': 'https://pe.tedcdn.com/i...   \n",
       "\n",
       "                     speaker_occupation  \\\n",
       "0                       Author/educator   \n",
       "1                      Climate advocate   \n",
       "2                  Technology columnist   \n",
       "3    Activist for environmental justice   \n",
       "4  Global health expert; data visionary   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['children', 'creativity', 'culture', 'dance',...   \n",
       "1  ['alternative energy', 'cars', 'climate change...   \n",
       "2  ['computers', 'entertainment', 'interface desi...   \n",
       "3  ['MacArthur grant', 'activism', 'business', 'c...   \n",
       "4  ['Africa', 'Asia', 'Google', 'demo', 'economic...   \n",
       "\n",
       "                             title  \\\n",
       "0      Do schools kill creativity?   \n",
       "1      Averting the climate crisis   \n",
       "2                 Simplicity sells   \n",
       "3              Greening the ghetto   \n",
       "4  The best stats you've ever seen   \n",
       "\n",
       "                                                 url     views  \n",
       "0  https://www.ted.com/talks/ken_robinson_says_sc...  47227110  \n",
       "1  https://www.ted.com/talks/al_gore_on_averting_...   3200520  \n",
       "2  https://www.ted.com/talks/david_pogue_says_sim...   1636292  \n",
       "3  https://www.ted.com/talks/majora_carter_s_tale...   1697550  \n",
       "4  https://www.ted.com/talks/hans_rosling_shows_t...  12005869  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = pd.read_csv('data/transcripts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_merged = pd.merge(left=transcripts, right=ted_main, left_on='url', right_on='url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>url</th>\n",
       "      <th>comments</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "      <th>film_date</th>\n",
       "      <th>languages</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>name</th>\n",
       "      <th>num_speaker</th>\n",
       "      <th>published_date</th>\n",
       "      <th>ratings</th>\n",
       "      <th>related_talks</th>\n",
       "      <th>speaker_occupation</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning. How are you?(Laughter)It's been ...</td>\n",
       "      <td>https://www.ted.com/talks/ken_robinson_says_sc...</td>\n",
       "      <td>4553</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>1164</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140825600</td>\n",
       "      <td>60</td>\n",
       "      <td>Ken Robinson</td>\n",
       "      <td>Ken Robinson: Do schools kill creativity?</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>[{'id': 7, 'name': 'Funny', 'count': 19645}, {...</td>\n",
       "      <td>[{'id': 865, 'hero': 'https://pe.tedcdn.com/im...</td>\n",
       "      <td>Author/educator</td>\n",
       "      <td>['children', 'creativity', 'culture', 'dance',...</td>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>47227110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
       "      <td>https://www.ted.com/talks/al_gore_on_averting_...</td>\n",
       "      <td>265</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>977</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140825600</td>\n",
       "      <td>43</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Al Gore: Averting the climate crisis</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>[{'id': 7, 'name': 'Funny', 'count': 544}, {'i...</td>\n",
       "      <td>[{'id': 243, 'hero': 'https://pe.tedcdn.com/im...</td>\n",
       "      <td>Climate advocate</td>\n",
       "      <td>['alternative energy', 'cars', 'climate change...</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>3200520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Music: \"The Sound of Silence,\" Simon &amp; Garfun...</td>\n",
       "      <td>https://www.ted.com/talks/david_pogue_says_sim...</td>\n",
       "      <td>124</td>\n",
       "      <td>New York Times columnist David Pogue takes aim...</td>\n",
       "      <td>1286</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140739200</td>\n",
       "      <td>26</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>David Pogue: Simplicity sells</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>[{'id': 7, 'name': 'Funny', 'count': 964}, {'i...</td>\n",
       "      <td>[{'id': 1725, 'hero': 'https://pe.tedcdn.com/i...</td>\n",
       "      <td>Technology columnist</td>\n",
       "      <td>['computers', 'entertainment', 'interface desi...</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>1636292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you're here today — and I'm very happy that...</td>\n",
       "      <td>https://www.ted.com/talks/majora_carter_s_tale...</td>\n",
       "      <td>200</td>\n",
       "      <td>In an emotionally charged talk, MacArthur-winn...</td>\n",
       "      <td>1116</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140912000</td>\n",
       "      <td>35</td>\n",
       "      <td>Majora Carter</td>\n",
       "      <td>Majora Carter: Greening the ghetto</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>[{'id': 3, 'name': 'Courageous', 'count': 760}...</td>\n",
       "      <td>[{'id': 1041, 'hero': 'https://pe.tedcdn.com/i...</td>\n",
       "      <td>Activist for environmental justice</td>\n",
       "      <td>['MacArthur grant', 'activism', 'business', 'c...</td>\n",
       "      <td>Greening the ghetto</td>\n",
       "      <td>1697550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>About 10 years ago, I took on the task to teac...</td>\n",
       "      <td>https://www.ted.com/talks/hans_rosling_shows_t...</td>\n",
       "      <td>593</td>\n",
       "      <td>You've never seen data presented like this. Wi...</td>\n",
       "      <td>1190</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140566400</td>\n",
       "      <td>48</td>\n",
       "      <td>Hans Rosling</td>\n",
       "      <td>Hans Rosling: The best stats you've ever seen</td>\n",
       "      <td>1</td>\n",
       "      <td>1151440680</td>\n",
       "      <td>[{'id': 9, 'name': 'Ingenious', 'count': 3202}...</td>\n",
       "      <td>[{'id': 2056, 'hero': 'https://pe.tedcdn.com/i...</td>\n",
       "      <td>Global health expert; data visionary</td>\n",
       "      <td>['Africa', 'Asia', 'Google', 'demo', 'economic...</td>\n",
       "      <td>The best stats you've ever seen</td>\n",
       "      <td>12005869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript  \\\n",
       "0  Good morning. How are you?(Laughter)It's been ...   \n",
       "1  Thank you so much, Chris. And it's truly a gre...   \n",
       "2  (Music: \"The Sound of Silence,\" Simon & Garfun...   \n",
       "3  If you're here today — and I'm very happy that...   \n",
       "4  About 10 years ago, I took on the task to teac...   \n",
       "\n",
       "                                                 url  comments  \\\n",
       "0  https://www.ted.com/talks/ken_robinson_says_sc...      4553   \n",
       "1  https://www.ted.com/talks/al_gore_on_averting_...       265   \n",
       "2  https://www.ted.com/talks/david_pogue_says_sim...       124   \n",
       "3  https://www.ted.com/talks/majora_carter_s_tale...       200   \n",
       "4  https://www.ted.com/talks/hans_rosling_shows_t...       593   \n",
       "\n",
       "                                         description  duration    event  \\\n",
       "0  Sir Ken Robinson makes an entertaining and pro...      1164  TED2006   \n",
       "1  With the same humor and humanity he exuded in ...       977  TED2006   \n",
       "2  New York Times columnist David Pogue takes aim...      1286  TED2006   \n",
       "3  In an emotionally charged talk, MacArthur-winn...      1116  TED2006   \n",
       "4  You've never seen data presented like this. Wi...      1190  TED2006   \n",
       "\n",
       "    film_date  languages   main_speaker  \\\n",
       "0  1140825600         60   Ken Robinson   \n",
       "1  1140825600         43        Al Gore   \n",
       "2  1140739200         26    David Pogue   \n",
       "3  1140912000         35  Majora Carter   \n",
       "4  1140566400         48   Hans Rosling   \n",
       "\n",
       "                                            name  num_speaker  published_date  \\\n",
       "0      Ken Robinson: Do schools kill creativity?            1      1151367060   \n",
       "1           Al Gore: Averting the climate crisis            1      1151367060   \n",
       "2                  David Pogue: Simplicity sells            1      1151367060   \n",
       "3             Majora Carter: Greening the ghetto            1      1151367060   \n",
       "4  Hans Rosling: The best stats you've ever seen            1      1151440680   \n",
       "\n",
       "                                             ratings  \\\n",
       "0  [{'id': 7, 'name': 'Funny', 'count': 19645}, {...   \n",
       "1  [{'id': 7, 'name': 'Funny', 'count': 544}, {'i...   \n",
       "2  [{'id': 7, 'name': 'Funny', 'count': 964}, {'i...   \n",
       "3  [{'id': 3, 'name': 'Courageous', 'count': 760}...   \n",
       "4  [{'id': 9, 'name': 'Ingenious', 'count': 3202}...   \n",
       "\n",
       "                                       related_talks  \\\n",
       "0  [{'id': 865, 'hero': 'https://pe.tedcdn.com/im...   \n",
       "1  [{'id': 243, 'hero': 'https://pe.tedcdn.com/im...   \n",
       "2  [{'id': 1725, 'hero': 'https://pe.tedcdn.com/i...   \n",
       "3  [{'id': 1041, 'hero': 'https://pe.tedcdn.com/i...   \n",
       "4  [{'id': 2056, 'hero': 'https://pe.tedcdn.com/i...   \n",
       "\n",
       "                     speaker_occupation  \\\n",
       "0                       Author/educator   \n",
       "1                      Climate advocate   \n",
       "2                  Technology columnist   \n",
       "3    Activist for environmental justice   \n",
       "4  Global health expert; data visionary   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['children', 'creativity', 'culture', 'dance',...   \n",
       "1  ['alternative energy', 'cars', 'climate change...   \n",
       "2  ['computers', 'entertainment', 'interface desi...   \n",
       "3  ['MacArthur grant', 'activism', 'business', 'c...   \n",
       "4  ['Africa', 'Asia', 'Google', 'demo', 'economic...   \n",
       "\n",
       "                             title     views  \n",
       "0      Do schools kill creativity?  47227110  \n",
       "1      Averting the climate crisis   3200520  \n",
       "2                 Simplicity sells   1636292  \n",
       "3              Greening the ghetto   1697550  \n",
       "4  The best stats you've ever seen  12005869  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = ted_merged.transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_num(input_str):\n",
    "    return re.sub(r'\\d+', '', input_str)\n",
    "\n",
    "transcript = transcript.apply(contractions.fix) # remove contractions\n",
    "transcript = transcript.str.lower() # lowercase\n",
    "transcript = transcript.apply(rm_num) # remove numbers\n",
    "specials = '()'\n",
    "transcript = transcript.str.translate(str.maketrans('()',' '*len(specials))) # remove par around laughter\n",
    "transcript = transcript.str.translate(str.maketrans('','',string.punctuation)) # remove punctuation\n",
    "transscipt = transcript.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall sentiment dictionary is :  {'neg': 0.043, 'neu': 0.805, 'pos': 0.152, 'compound': 0.9999}\n",
      "sentence was rated as  4.3 % Negative\n",
      "sentence was rated as  80.5 % Neutral\n",
      "sentence was rated as  15.2 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.038, 'neu': 0.82, 'pos': 0.142, 'compound': 0.9998}\n",
      "sentence was rated as  3.8 % Negative\n",
      "sentence was rated as  82.0 % Neutral\n",
      "sentence was rated as  14.2 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.062, 'neu': 0.782, 'pos': 0.155, 'compound': 0.9999}\n",
      "sentence was rated as  6.2 % Negative\n",
      "sentence was rated as  78.2 % Neutral\n",
      "sentence was rated as  15.5 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.073, 'neu': 0.774, 'pos': 0.153, 'compound': 0.9998}\n",
      "sentence was rated as  7.3 % Negative\n",
      "sentence was rated as  77.4 % Neutral\n",
      "sentence was rated as  15.299999999999999 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.049, 'neu': 0.839, 'pos': 0.112, 'compound': 0.9997}\n",
      "sentence was rated as  4.9 % Negative\n",
      "sentence was rated as  83.89999999999999 % Neutral\n",
      "sentence was rated as  11.200000000000001 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.08, 'neu': 0.774, 'pos': 0.147, 'compound': 0.9999}\n",
      "sentence was rated as  8.0 % Negative\n",
      "sentence was rated as  77.4 % Neutral\n",
      "sentence was rated as  14.7 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.073, 'neu': 0.735, 'pos': 0.191, 'compound': 0.9999}\n",
      "sentence was rated as  7.3 % Negative\n",
      "sentence was rated as  73.5 % Neutral\n",
      "sentence was rated as  19.1 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.035, 'neu': 0.894, 'pos': 0.071, 'compound': 0.9991}\n",
      "sentence was rated as  3.5000000000000004 % Negative\n",
      "sentence was rated as  89.4 % Neutral\n",
      "sentence was rated as  7.1 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.057, 'neu': 0.782, 'pos': 0.161, 'compound': 0.9999}\n",
      "sentence was rated as  5.7 % Negative\n",
      "sentence was rated as  78.2 % Neutral\n",
      "sentence was rated as  16.1 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.04, 'neu': 0.836, 'pos': 0.125, 'compound': 0.9999}\n",
      "sentence was rated as  4.0 % Negative\n",
      "sentence was rated as  83.6 % Neutral\n",
      "sentence was rated as  12.5 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.039, 'neu': 0.862, 'pos': 0.099, 'compound': 0.9997}\n",
      "sentence was rated as  3.9 % Negative\n",
      "sentence was rated as  86.2 % Neutral\n",
      "sentence was rated as  9.9 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.071, 'neu': 0.809, 'pos': 0.12, 'compound': 0.9997}\n",
      "sentence was rated as  7.1 % Negative\n",
      "sentence was rated as  80.9 % Neutral\n",
      "sentence was rated as  12.0 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.086, 'neu': 0.819, 'pos': 0.095, 'compound': 0.9847}\n",
      "sentence was rated as  8.6 % Negative\n",
      "sentence was rated as  81.89999999999999 % Neutral\n",
      "sentence was rated as  9.5 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.025, 'neu': 0.853, 'pos': 0.122, 'compound': 0.9995}\n",
      "sentence was rated as  2.5 % Negative\n",
      "sentence was rated as  85.3 % Neutral\n",
      "sentence was rated as  12.2 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.045, 'neu': 0.836, 'pos': 0.119, 'compound': 0.9998}\n",
      "sentence was rated as  4.5 % Negative\n",
      "sentence was rated as  83.6 % Neutral\n",
      "sentence was rated as  11.899999999999999 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.041, 'neu': 0.699, 'pos': 0.26, 'compound': 0.9996}\n",
      "sentence was rated as  4.1000000000000005 % Negative\n",
      "sentence was rated as  69.89999999999999 % Neutral\n",
      "sentence was rated as  26.0 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.022, 'neu': 0.788, 'pos': 0.19, 'compound': 0.9996}\n",
      "sentence was rated as  2.1999999999999997 % Negative\n",
      "sentence was rated as  78.8 % Neutral\n",
      "sentence was rated as  19.0 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.051, 'neu': 0.838, 'pos': 0.111, 'compound': 0.9996}\n",
      "sentence was rated as  5.1 % Negative\n",
      "sentence was rated as  83.8 % Neutral\n",
      "sentence was rated as  11.1 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.029, 'neu': 0.842, 'pos': 0.129, 'compound': 0.9999}\n",
      "sentence was rated as  2.9000000000000004 % Negative\n",
      "sentence was rated as  84.2 % Neutral\n",
      "sentence was rated as  12.9 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.043, 'neu': 0.842, 'pos': 0.115, 'compound': 0.9999}\n",
      "sentence was rated as  4.3 % Negative\n",
      "sentence was rated as  84.2 % Neutral\n",
      "sentence was rated as  11.5 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Overall sentiment dictionary is :  {'neg': 0.013, 'neu': 0.861, 'pos': 0.126, 'compound': 0.9999}\n",
      "sentence was rated as  1.3 % Negative\n",
      "sentence was rated as  86.1 % Neutral\n",
      "sentence was rated as  12.6 % Positive\n",
      "Sentence Overall Rated As Positive\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-cecafa0d4928>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# setiment analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtransscipts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-79c3eff15ac2>\u001b[0m in \u001b[0;36msentiment_scores\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# oject gives a sentiment dictionary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# which contains pos, neg, neu, and compound scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0msentiment_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msid_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Overall sentiment dictionary is : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/vaderSentiment/vaderSentiment.py\u001b[0m in \u001b[0;36mpolarity_scores\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0msentiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment_valence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentitext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0msentiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_but_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_and_emoticons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/vaderSentiment/vaderSentiment.py\u001b[0m in \u001b[0;36msentiment_valence\u001b[0;34m(self, valence, sentitext, item, i, sentiments)\u001b[0m\n\u001b[1;32m    310\u001b[0m                         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                     \u001b[0mvalence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalence\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                     \u001b[0mvalence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_negation_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_and_emoticons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mstart_i\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                         \u001b[0mvalence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_special_idioms_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_and_emoticons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/vaderSentiment/vaderSentiment.py\u001b[0m in \u001b[0;36m_negation_check\u001b[0;34m(valence, words_and_emoticons, start_i, i)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_negation_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_and_emoticons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mwords_and_emoticons_lower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords_and_emoticons\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart_i\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnegated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwords_and_emoticons_lower\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 1 word preceding lexicon word (w/o stopwords)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/vaderSentiment/vaderSentiment.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_negation_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_and_emoticons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mwords_and_emoticons_lower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords_and_emoticons\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart_i\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnegated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwords_and_emoticons_lower\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 1 word preceding lexicon word (w/o stopwords)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# setiment analysis\n",
    "transscipts.apply(sentiment_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# transcripts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Word2Vec(common_texts, size=100, window=5, min_count=1, workers=4)\n",
    "model = KeyedVectors.load_word2vec_format('~/weight/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "# model.wv['computer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ! nltk.download('punkt')\n",
    "stemmer = PorterStemmer()\n",
    "vec_embeddings = {}\n",
    "for i, transcript in enumerate(transcripts):\n",
    "    vec_embeddings[i] = [stemmer.stem(word) for word in word_tokenize(transcript) if not word in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'morn',\n",
       " 'laughter',\n",
       " 'great',\n",
       " 'blown',\n",
       " 'away',\n",
       " 'whole',\n",
       " 'thing',\n",
       " 'fact',\n",
       " 'leav',\n",
       " 'laughter',\n",
       " 'three',\n",
       " 'theme',\n",
       " 'run',\n",
       " 'confer',\n",
       " 'relev',\n",
       " 'want',\n",
       " 'talk',\n",
       " 'one',\n",
       " 'extraordinari',\n",
       " 'evid',\n",
       " 'human',\n",
       " 'creativ',\n",
       " 'present',\n",
       " 'peopl',\n",
       " 'varieti',\n",
       " 'rang',\n",
       " 'second',\n",
       " 'put',\n",
       " 'us',\n",
       " 'place',\n",
       " 'idea',\n",
       " 'go',\n",
       " 'happen',\n",
       " 'term',\n",
       " 'futur',\n",
       " 'idea',\n",
       " 'may',\n",
       " 'play',\n",
       " 'outi',\n",
       " 'interest',\n",
       " 'educ',\n",
       " 'actual',\n",
       " 'find',\n",
       " 'everybodi',\n",
       " 'interest',\n",
       " 'educ',\n",
       " 'find',\n",
       " 'interest',\n",
       " 'dinner',\n",
       " 'parti',\n",
       " 'say',\n",
       " 'work',\n",
       " 'educ',\n",
       " '—',\n",
       " 'actual',\n",
       " 'often',\n",
       " 'dinner',\n",
       " 'parti',\n",
       " 'frankli',\n",
       " 'laughter',\n",
       " 'work',\n",
       " 'educ',\n",
       " 'ask',\n",
       " 'laughter',\n",
       " 'never',\n",
       " 'ask',\n",
       " 'back',\n",
       " 'curious',\n",
       " 'strang',\n",
       " 'say',\n",
       " 'somebodi',\n",
       " 'know',\n",
       " 'say',\n",
       " 'say',\n",
       " 'work',\n",
       " 'educ',\n",
       " 'see',\n",
       " 'blood',\n",
       " 'run',\n",
       " 'face',\n",
       " 'like',\n",
       " 'oh',\n",
       " 'god',\n",
       " 'know',\n",
       " 'laughter',\n",
       " 'one',\n",
       " 'night',\n",
       " 'week',\n",
       " 'laughter',\n",
       " 'ask',\n",
       " 'educ',\n",
       " 'pin',\n",
       " 'wall',\n",
       " 'one',\n",
       " 'thing',\n",
       " 'goe',\n",
       " 'deep',\n",
       " 'peopl',\n",
       " 'right',\n",
       " 'like',\n",
       " 'religion',\n",
       " 'money',\n",
       " 'thing',\n",
       " 'big',\n",
       " 'interest',\n",
       " 'educ',\n",
       " 'think',\n",
       " 'huge',\n",
       " 'vest',\n",
       " 'interest',\n",
       " 'partli',\n",
       " 'educ',\n",
       " 'meant',\n",
       " 'take',\n",
       " 'us',\n",
       " 'futur',\n",
       " 'grasp',\n",
       " 'think',\n",
       " 'children',\n",
       " 'start',\n",
       " 'school',\n",
       " 'year',\n",
       " 'retir',\n",
       " 'nobodi',\n",
       " 'clue',\n",
       " 'despit',\n",
       " 'expertis',\n",
       " 'parad',\n",
       " 'past',\n",
       " 'four',\n",
       " 'day',\n",
       " 'world',\n",
       " 'look',\n",
       " 'like',\n",
       " 'five',\n",
       " 'year',\n",
       " 'time',\n",
       " 'yet',\n",
       " 'meant',\n",
       " 'educ',\n",
       " 'unpredict',\n",
       " 'think',\n",
       " 'extraordinaryand',\n",
       " 'third',\n",
       " 'part',\n",
       " 'agre',\n",
       " 'nonetheless',\n",
       " 'realli',\n",
       " 'extraordinari',\n",
       " 'capac',\n",
       " 'children',\n",
       " '—',\n",
       " 'capac',\n",
       " 'innov',\n",
       " 'mean',\n",
       " 'sirena',\n",
       " 'last',\n",
       " 'night',\n",
       " 'marvel',\n",
       " 'see',\n",
       " 'could',\n",
       " 'except',\n",
       " 'think',\n",
       " 'speak',\n",
       " 'except',\n",
       " 'whole',\n",
       " 'childhood',\n",
       " 'person',\n",
       " 'extraordinari',\n",
       " 'dedic',\n",
       " 'found',\n",
       " 'talent',\n",
       " 'content',\n",
       " 'kid',\n",
       " 'tremend',\n",
       " 'talent',\n",
       " 'squander',\n",
       " 'pretti',\n",
       " 'ruthlesslyso',\n",
       " 'want',\n",
       " 'talk',\n",
       " 'educ',\n",
       " 'want',\n",
       " 'talk',\n",
       " 'creativ',\n",
       " 'content',\n",
       " 'creativ',\n",
       " 'import',\n",
       " 'educ',\n",
       " 'literaci',\n",
       " 'treat',\n",
       " 'statu',\n",
       " 'applaus',\n",
       " 'thank',\n",
       " 'applaus',\n",
       " 'way',\n",
       " 'thank',\n",
       " 'much',\n",
       " 'laughter',\n",
       " 'minut',\n",
       " 'left',\n",
       " 'laughter',\n",
       " 'well',\n",
       " 'born',\n",
       " 'laughter',\n",
       " 'heard',\n",
       " 'great',\n",
       " 'stori',\n",
       " 'recent',\n",
       " '—',\n",
       " 'love',\n",
       " 'tell',\n",
       " '—',\n",
       " 'littl',\n",
       " 'girl',\n",
       " 'draw',\n",
       " 'lesson',\n",
       " 'six',\n",
       " 'back',\n",
       " 'draw',\n",
       " 'teacher',\n",
       " 'said',\n",
       " 'girl',\n",
       " 'hardli',\n",
       " 'ever',\n",
       " 'paid',\n",
       " 'attent',\n",
       " 'draw',\n",
       " 'lesson',\n",
       " 'teacher',\n",
       " 'fascin',\n",
       " 'went',\n",
       " 'said',\n",
       " 'draw',\n",
       " 'girl',\n",
       " 'said',\n",
       " 'draw',\n",
       " 'pictur',\n",
       " 'god',\n",
       " 'teacher',\n",
       " 'said',\n",
       " 'nobodi',\n",
       " 'know',\n",
       " 'god',\n",
       " 'look',\n",
       " 'like',\n",
       " 'girl',\n",
       " 'said',\n",
       " 'minut',\n",
       " 'laughter',\n",
       " 'son',\n",
       " 'four',\n",
       " 'england',\n",
       " '—',\n",
       " 'actual',\n",
       " 'four',\n",
       " 'everywher',\n",
       " 'honest',\n",
       " 'laughter',\n",
       " 'strict',\n",
       " 'wherev',\n",
       " 'went',\n",
       " 'four',\n",
       " 'year',\n",
       " 'nativ',\n",
       " 'play',\n",
       " 'rememb',\n",
       " 'stori',\n",
       " 'laughter',\n",
       " 'big',\n",
       " 'big',\n",
       " 'stori',\n",
       " 'mel',\n",
       " 'gibson',\n",
       " 'sequel',\n",
       " 'may',\n",
       " 'seen',\n",
       " 'laughter',\n",
       " 'nativ',\n",
       " 'ii',\n",
       " 'jame',\n",
       " 'got',\n",
       " 'part',\n",
       " 'joseph',\n",
       " 'thrill',\n",
       " 'consid',\n",
       " 'one',\n",
       " 'lead',\n",
       " 'part',\n",
       " 'place',\n",
       " 'cram',\n",
       " 'full',\n",
       " 'agent',\n",
       " 'tshirt',\n",
       " 'jame',\n",
       " 'robinson',\n",
       " 'joseph',\n",
       " 'laughter',\n",
       " 'speak',\n",
       " 'know',\n",
       " 'bit',\n",
       " 'three',\n",
       " 'king',\n",
       " 'come',\n",
       " 'come',\n",
       " 'bear',\n",
       " 'gift',\n",
       " 'gold',\n",
       " 'frankincens',\n",
       " 'myrrh',\n",
       " 'realli',\n",
       " 'happen',\n",
       " 'sit',\n",
       " 'think',\n",
       " 'went',\n",
       " 'sequenc',\n",
       " 'talk',\n",
       " 'littl',\n",
       " 'boy',\n",
       " 'afterward',\n",
       " 'said',\n",
       " 'ok',\n",
       " 'said',\n",
       " 'yeah',\n",
       " 'wrong',\n",
       " 'switch',\n",
       " 'three',\n",
       " 'boy',\n",
       " 'came',\n",
       " 'fouryearold',\n",
       " 'tea',\n",
       " 'towel',\n",
       " 'head',\n",
       " 'put',\n",
       " 'box',\n",
       " 'first',\n",
       " 'boy',\n",
       " 'said',\n",
       " 'bring',\n",
       " 'gold',\n",
       " 'second',\n",
       " 'boy',\n",
       " 'said',\n",
       " 'bring',\n",
       " 'myrrh',\n",
       " 'third',\n",
       " 'boy',\n",
       " 'said',\n",
       " 'frank',\n",
       " 'sent',\n",
       " 'laughter',\n",
       " 'thing',\n",
       " 'common',\n",
       " 'kid',\n",
       " 'take',\n",
       " 'chanc',\n",
       " 'know',\n",
       " 'go',\n",
       " 'right',\n",
       " 'frighten',\n",
       " 'wrong',\n",
       " 'mean',\n",
       " 'say',\n",
       " 'wrong',\n",
       " 'thing',\n",
       " 'creativ',\n",
       " 'know',\n",
       " 'prepar',\n",
       " 'wrong',\n",
       " 'never',\n",
       " 'come',\n",
       " 'anyth',\n",
       " 'origin',\n",
       " '—',\n",
       " 'prepar',\n",
       " 'wrong',\n",
       " 'time',\n",
       " 'get',\n",
       " 'adult',\n",
       " 'kid',\n",
       " 'lost',\n",
       " 'capac',\n",
       " 'becom',\n",
       " 'frighten',\n",
       " 'wrong',\n",
       " 'run',\n",
       " 'compani',\n",
       " 'like',\n",
       " 'stigmat',\n",
       " 'mistak',\n",
       " 'run',\n",
       " 'nation',\n",
       " 'educ',\n",
       " 'system',\n",
       " 'mistak',\n",
       " 'worst',\n",
       " 'thing',\n",
       " 'make',\n",
       " 'result',\n",
       " 'educ',\n",
       " 'peopl',\n",
       " 'creativ',\n",
       " 'capacitiespicasso',\n",
       " 'said',\n",
       " 'said',\n",
       " 'children',\n",
       " 'born',\n",
       " 'artist',\n",
       " 'problem',\n",
       " 'remain',\n",
       " 'artist',\n",
       " 'grow',\n",
       " 'believ',\n",
       " 'passion',\n",
       " 'grow',\n",
       " 'creativ',\n",
       " 'grow',\n",
       " 'rather',\n",
       " 'get',\n",
       " 'educ',\n",
       " 'thisi',\n",
       " 'live',\n",
       " 'stratfordonavon',\n",
       " 'five',\n",
       " 'year',\n",
       " 'ago',\n",
       " 'fact',\n",
       " 'move',\n",
       " 'stratford',\n",
       " 'lo',\n",
       " 'angel',\n",
       " 'imagin',\n",
       " 'seamless',\n",
       " 'transit',\n",
       " 'laughter',\n",
       " 'actual',\n",
       " 'live',\n",
       " 'place',\n",
       " 'call',\n",
       " 'snitterfield',\n",
       " 'outsid',\n",
       " 'stratford',\n",
       " 'shakespear',\n",
       " 'father',\n",
       " 'born',\n",
       " 'struck',\n",
       " 'new',\n",
       " 'thought',\n",
       " 'think',\n",
       " 'shakespear',\n",
       " 'father',\n",
       " 'think',\n",
       " 'shakespear',\n",
       " 'child',\n",
       " 'shakespear',\n",
       " 'seven',\n",
       " 'never',\n",
       " 'thought',\n",
       " 'mean',\n",
       " 'seven',\n",
       " 'point',\n",
       " 'somebodi',\n",
       " 'english',\n",
       " 'class',\n",
       " 'laughter',\n",
       " 'annoy',\n",
       " 'would',\n",
       " 'laughter',\n",
       " 'must',\n",
       " 'tri',\n",
       " 'harder',\n",
       " 'laughter',\n",
       " 'sent',\n",
       " 'bed',\n",
       " 'dad',\n",
       " 'know',\n",
       " 'shakespear',\n",
       " 'go',\n",
       " 'bed',\n",
       " 'put',\n",
       " 'pencil',\n",
       " 'laughter',\n",
       " 'stop',\n",
       " 'speak',\n",
       " 'like',\n",
       " 'laughter',\n",
       " 'confus',\n",
       " 'everybodi',\n",
       " 'laughter',\n",
       " 'anyway',\n",
       " 'move',\n",
       " 'stratford',\n",
       " 'lo',\n",
       " 'angel',\n",
       " 'want',\n",
       " 'say',\n",
       " 'word',\n",
       " 'transit',\n",
       " 'son',\n",
       " 'want',\n",
       " 'come',\n",
       " 'got',\n",
       " 'two',\n",
       " 'kid',\n",
       " 'daughter',\n",
       " 'want',\n",
       " 'come',\n",
       " 'lo',\n",
       " 'angel',\n",
       " 'love',\n",
       " 'girlfriend',\n",
       " 'england',\n",
       " 'love',\n",
       " 'life',\n",
       " 'sarah',\n",
       " 'would',\n",
       " 'known',\n",
       " 'month',\n",
       " 'laughter',\n",
       " 'mind',\n",
       " 'would',\n",
       " 'fourth',\n",
       " 'anniversari',\n",
       " 'long',\n",
       " 'time',\n",
       " 'realli',\n",
       " 'upset',\n",
       " 'plane',\n",
       " 'said',\n",
       " 'never',\n",
       " 'find',\n",
       " 'anoth',\n",
       " 'girl',\n",
       " 'like',\n",
       " 'sarah',\n",
       " 'rather',\n",
       " 'pleas',\n",
       " 'frankli',\n",
       " '—',\n",
       " 'laughter',\n",
       " 'main',\n",
       " 'reason',\n",
       " 'leav',\n",
       " 'countri',\n",
       " 'laughter',\n",
       " 'someth',\n",
       " 'strike',\n",
       " 'move',\n",
       " 'america',\n",
       " 'travel',\n",
       " 'around',\n",
       " 'world',\n",
       " 'everi',\n",
       " 'educ',\n",
       " 'system',\n",
       " 'earth',\n",
       " 'hierarchi',\n",
       " 'subject',\n",
       " 'everi',\n",
       " 'one',\n",
       " 'matter',\n",
       " 'go',\n",
       " 'would',\n",
       " 'think',\n",
       " 'would',\n",
       " 'otherwis',\n",
       " 'top',\n",
       " 'mathemat',\n",
       " 'languag',\n",
       " 'human',\n",
       " 'bottom',\n",
       " 'art',\n",
       " 'everywher',\n",
       " 'earth',\n",
       " 'pretti',\n",
       " 'much',\n",
       " 'everi',\n",
       " 'system',\n",
       " 'hierarchi',\n",
       " 'within',\n",
       " 'art',\n",
       " 'art',\n",
       " 'music',\n",
       " 'normal',\n",
       " 'given',\n",
       " 'higher',\n",
       " 'statu',\n",
       " 'school',\n",
       " 'drama',\n",
       " 'danc',\n",
       " 'educ',\n",
       " 'system',\n",
       " 'planet',\n",
       " 'teach',\n",
       " 'danc',\n",
       " 'everyday',\n",
       " 'children',\n",
       " 'way',\n",
       " 'teach',\n",
       " 'mathemat',\n",
       " 'think',\n",
       " 'rather',\n",
       " 'import',\n",
       " 'think',\n",
       " 'math',\n",
       " 'import',\n",
       " 'danc',\n",
       " 'children',\n",
       " 'danc',\n",
       " 'time',\n",
       " 'allow',\n",
       " 'bodi',\n",
       " 'miss',\n",
       " 'meet',\n",
       " 'laughter',\n",
       " 'truth',\n",
       " 'happen',\n",
       " 'children',\n",
       " 'grow',\n",
       " 'start',\n",
       " 'educ',\n",
       " 'progress',\n",
       " 'waist',\n",
       " 'focu',\n",
       " 'head',\n",
       " 'slightli',\n",
       " 'one',\n",
       " 'sideif',\n",
       " 'visit',\n",
       " 'educ',\n",
       " 'alien',\n",
       " 'say',\n",
       " 'public',\n",
       " 'educ',\n",
       " 'think',\n",
       " 'would',\n",
       " 'conclud',\n",
       " 'look',\n",
       " 'output',\n",
       " 'realli',\n",
       " 'succe',\n",
       " 'everyth',\n",
       " 'get',\n",
       " 'browni',\n",
       " 'point',\n",
       " 'winner',\n",
       " '—',\n",
       " 'think',\n",
       " 'would',\n",
       " 'conclud',\n",
       " 'whole',\n",
       " 'purpos',\n",
       " 'public',\n",
       " 'educ',\n",
       " 'throughout',\n",
       " 'world',\n",
       " 'produc',\n",
       " 'univers',\n",
       " 'professor',\n",
       " 'peopl',\n",
       " 'come',\n",
       " 'top',\n",
       " 'use',\n",
       " 'one',\n",
       " 'laughter',\n",
       " 'like',\n",
       " 'univers',\n",
       " 'professor',\n",
       " 'know',\n",
       " 'hold',\n",
       " 'highwat',\n",
       " 'mark',\n",
       " 'human',\n",
       " 'achiev',\n",
       " 'form',\n",
       " 'life',\n",
       " 'anoth',\n",
       " 'form',\n",
       " 'life',\n",
       " 'rather',\n",
       " 'curiou',\n",
       " 'say',\n",
       " 'affect',\n",
       " 'someth',\n",
       " 'curiou',\n",
       " 'professor',\n",
       " 'experi',\n",
       " '—',\n",
       " 'typic',\n",
       " 'live',\n",
       " 'head',\n",
       " 'live',\n",
       " 'slightli',\n",
       " 'one',\n",
       " 'side',\n",
       " 'disembodi',\n",
       " 'know',\n",
       " 'kind',\n",
       " 'liter',\n",
       " 'way',\n",
       " 'look',\n",
       " 'upon',\n",
       " 'bodi',\n",
       " 'form',\n",
       " 'transport',\n",
       " 'head',\n",
       " 'laughter',\n",
       " 'way',\n",
       " 'get',\n",
       " 'head',\n",
       " 'meet',\n",
       " 'laughter',\n",
       " 'want',\n",
       " 'real',\n",
       " 'evid',\n",
       " 'outofbodi',\n",
       " 'experi',\n",
       " 'get',\n",
       " 'along',\n",
       " 'residenti',\n",
       " 'confer',\n",
       " 'senior',\n",
       " 'academ',\n",
       " 'pop',\n",
       " 'discothequ',\n",
       " 'final',\n",
       " 'night',\n",
       " 'laughter',\n",
       " 'see',\n",
       " 'grown',\n",
       " 'men',\n",
       " 'women',\n",
       " 'writh',\n",
       " 'uncontrol',\n",
       " 'beat',\n",
       " 'laughter',\n",
       " 'wait',\n",
       " 'end',\n",
       " 'go',\n",
       " 'home',\n",
       " 'write',\n",
       " 'paper',\n",
       " 'laughter',\n",
       " 'educ',\n",
       " 'system',\n",
       " 'predic',\n",
       " 'idea',\n",
       " 'academ',\n",
       " 'abil',\n",
       " 'reason',\n",
       " 'around',\n",
       " 'world',\n",
       " 'public',\n",
       " 'system',\n",
       " 'educ',\n",
       " 'realli',\n",
       " 'th',\n",
       " 'centuri',\n",
       " 'came',\n",
       " 'meet',\n",
       " 'need',\n",
       " 'industri',\n",
       " 'hierarchi',\n",
       " 'root',\n",
       " 'two',\n",
       " 'ideasnumb',\n",
       " 'one',\n",
       " 'use',\n",
       " 'subject',\n",
       " 'work',\n",
       " 'top',\n",
       " 'probabl',\n",
       " 'steer',\n",
       " 'benignli',\n",
       " 'away',\n",
       " 'thing',\n",
       " 'school',\n",
       " 'kid',\n",
       " 'thing',\n",
       " 'like',\n",
       " 'ground',\n",
       " 'would',\n",
       " 'never',\n",
       " 'get',\n",
       " 'job',\n",
       " 'right',\n",
       " 'music',\n",
       " 'go',\n",
       " 'musician',\n",
       " 'art',\n",
       " 'artist',\n",
       " 'benign',\n",
       " 'advic',\n",
       " '—',\n",
       " 'profoundli',\n",
       " 'mistaken',\n",
       " 'whole',\n",
       " 'world',\n",
       " 'engulf',\n",
       " 'revolutionand',\n",
       " 'second',\n",
       " 'academ',\n",
       " 'abil',\n",
       " 'realli',\n",
       " 'come',\n",
       " 'domin',\n",
       " 'view',\n",
       " 'intellig',\n",
       " 'univers',\n",
       " 'design',\n",
       " 'system',\n",
       " 'imag',\n",
       " 'think',\n",
       " 'whole',\n",
       " 'system',\n",
       " 'public',\n",
       " 'educ',\n",
       " 'around',\n",
       " 'world',\n",
       " 'protract',\n",
       " 'process',\n",
       " 'univers',\n",
       " 'entranc',\n",
       " 'consequ',\n",
       " 'mani',\n",
       " 'highlytal',\n",
       " 'brilliant',\n",
       " 'creativ',\n",
       " 'peopl',\n",
       " 'think',\n",
       " 'thing',\n",
       " 'good',\n",
       " 'school',\n",
       " 'valu',\n",
       " 'actual',\n",
       " 'stigmat',\n",
       " 'think',\n",
       " 'afford',\n",
       " 'go',\n",
       " 'wayin',\n",
       " 'next',\n",
       " 'year',\n",
       " 'accord',\n",
       " 'unesco',\n",
       " 'peopl',\n",
       " 'worldwid',\n",
       " 'graduat',\n",
       " 'educ',\n",
       " 'sinc',\n",
       " 'begin',\n",
       " 'histori',\n",
       " 'peopl',\n",
       " 'combin',\n",
       " 'thing',\n",
       " 'talk',\n",
       " '—',\n",
       " 'technolog',\n",
       " 'transform',\n",
       " 'effect',\n",
       " 'work',\n",
       " 'demographi',\n",
       " 'huge',\n",
       " 'explos',\n",
       " 'populationsuddenli',\n",
       " 'degre',\n",
       " 'worth',\n",
       " 'anyth',\n",
       " 'true',\n",
       " 'student',\n",
       " 'degre',\n",
       " 'job',\n",
       " 'job',\n",
       " 'want',\n",
       " 'one',\n",
       " 'want',\n",
       " 'one',\n",
       " 'frankli',\n",
       " 'laughter',\n",
       " 'kid',\n",
       " 'degre',\n",
       " 'often',\n",
       " 'head',\n",
       " 'home',\n",
       " 'carri',\n",
       " 'play',\n",
       " 'video',\n",
       " 'game',\n",
       " 'need',\n",
       " 'previou',\n",
       " 'job',\n",
       " 'requir',\n",
       " 'ba',\n",
       " 'need',\n",
       " 'phd',\n",
       " 'process',\n",
       " 'academ',\n",
       " 'inflat',\n",
       " 'indic',\n",
       " 'whole',\n",
       " 'structur',\n",
       " 'educ',\n",
       " 'shift',\n",
       " 'beneath',\n",
       " 'feet',\n",
       " 'need',\n",
       " 'radic',\n",
       " 'rethink',\n",
       " 'view',\n",
       " 'intelligencew',\n",
       " 'know',\n",
       " 'three',\n",
       " 'thing',\n",
       " 'intellig',\n",
       " 'one',\n",
       " 'divers',\n",
       " 'think',\n",
       " 'world',\n",
       " 'way',\n",
       " 'experi',\n",
       " 'think',\n",
       " 'visual',\n",
       " 'think',\n",
       " 'sound',\n",
       " 'think',\n",
       " 'kinesthet',\n",
       " 'think',\n",
       " 'abstract',\n",
       " 'term',\n",
       " 'think',\n",
       " 'movement',\n",
       " 'secondli',\n",
       " 'intellig',\n",
       " 'dynam',\n",
       " 'look',\n",
       " 'interact',\n",
       " 'human',\n",
       " 'brain',\n",
       " 'heard',\n",
       " 'yesterday',\n",
       " 'number',\n",
       " 'present',\n",
       " 'intellig',\n",
       " 'wonder',\n",
       " 'interact',\n",
       " 'brain',\n",
       " 'divid',\n",
       " 'compart',\n",
       " 'fact',\n",
       " 'creativ',\n",
       " '—',\n",
       " 'defin',\n",
       " 'process',\n",
       " 'origin',\n",
       " 'idea',\n",
       " 'valu',\n",
       " '—',\n",
       " 'often',\n",
       " 'come',\n",
       " 'interact',\n",
       " 'differ',\n",
       " 'disciplinari',\n",
       " 'way',\n",
       " 'see',\n",
       " 'thingsbi',\n",
       " 'way',\n",
       " 'shaft',\n",
       " 'nerv',\n",
       " 'join',\n",
       " 'two',\n",
       " 'halv',\n",
       " 'brain',\n",
       " 'call',\n",
       " 'corpu',\n",
       " 'callosum',\n",
       " 'thicker',\n",
       " 'women',\n",
       " 'follow',\n",
       " 'helen',\n",
       " 'yesterday',\n",
       " 'probabl',\n",
       " 'women',\n",
       " 'better',\n",
       " 'multitask',\n",
       " 'raft',\n",
       " 'research',\n",
       " 'know',\n",
       " 'person',\n",
       " 'life',\n",
       " 'wife',\n",
       " 'cook',\n",
       " 'meal',\n",
       " 'home',\n",
       " '—',\n",
       " 'often',\n",
       " 'thank',\n",
       " 'laughter',\n",
       " 'good',\n",
       " 'thing',\n",
       " 'cook',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_embeddings[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "590px",
    "left": "27px",
    "right": "20px",
    "top": "211px",
    "width": "336px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

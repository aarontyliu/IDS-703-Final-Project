knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, comment = NA)
library(tidyverse)
library(tidyverse)
library(text2vec)
library(tidytext)
data = read_csv('data/ted_expanded.csv')
ncol(data)
transcripts = data[['transcripts']]
tidy_skipgrams = transcripts %>%
unnest_tokens(ngram, text, token = "ngrams", n = 8) %>%
mutate(ngramID = row_number()) %>%
tidyr::unite(skipgramID, postID, ngramID) %>%
unnest_tokens(word, ngram)
library(tidytext)
tidy_skipgrams = transcripts %>%
unnest_tokens(ngram, text, token = "ngrams", n = 8) %>%
mutate(ngramID = row_number()) %>%
tidyr::unite(skipgramID, postID, ngramID) %>%
unnest_tokens(word, ngram)
library(widyr)
install.packages("widyr")
library(widyr)
tidy_skipgrams = transcripts %>%
unnest_tokens(ngram, text, token = "ngrams", n = 8) %>%
mutate(ngramID = row_number()) %>%
tidyr::unite(skipgramID, postID, ngramID) %>%
unnest_tokens(word, ngram)
transcripts
transcripts = data[['transcript']]
transcripts[1]
tidy_skipgrams = transcripts %>%
unnest_tokens(ngram, text, token = "ngrams", n = 8) %>%
mutate(ngramID = row_number()) %>%
tidyr::unite(skipgramID, postID, ngramID) %>%
unnest_tokens(word, ngram)
?unnest_tokens
transcripts = data['transcript']
tidy_skipgrams = transcripts %>%
unnest_tokens(ngram, text, token = "ngrams", n = 8) %>%
mutate(ngramID = row_number()) %>%
tidyr::unite(skipgramID, postID, ngramID) %>%
unnest_tokens(word, ngram)
transcripts %>%
unnest_tokens(ngram, text, token = "ngrams", n = 8)
tidy_skipgrams = transcripts %>%
unnest_tokens(ngram, transcript, token = "ngrams", n = 8) %>%
mutate(ngramID = row_number()) %>%
tidyr::unite(skipgramID, postID, ngramID) %>%
unnest_tokens(word, ngram)
data[1,]
transcripts = data %>% select(url, transcript)
tidy_skipgrams = transcripts %>%
unnest_tokens(ngram, transcript, token = "ngrams", n = 8) %>%
mutate(ngramID = row_number()) %>%
tidyr::unite(skipgramID, url, ngramID) %>%
unnest_tokens(word, ngram)
transcripts = transcripts[1:100,]
tidy_skipgrams = transcripts %>%
unnest_tokens(ngram, transcript, token = "ngrams", n = 8) %>%
mutate(ngramID = row_number()) %>%
tidyr::unite(skipgramID, url, ngramID) %>%
unnest_tokens(word, ngram)
tidy_skipgrams
unigram_probs = transcripts %>%
unnest_tokens(word, transcript) %>%
count(word, sort = TRUE) %>%
mutate(p = n / sum(n))
unigram_probs
skipgram_probs = tidy_skipgrams %>%
pairwise_count(word, skipgramID, diag = TRUE, sort = TRUE) %>%
mutate(p = n / sum(n))
normalized_prob = skipgram_probs %>%
filter(n > 20) %>%
rename(word1 = item1, word2 = item2) %>%
left_join(unigram_probs %>%
select(word1 = word, p1 = p),
by = "word1") %>%
left_join(unigram_probs %>%
select(word2 = word, p2 = p),
by = "word2") %>%
mutate(p_together = p / p1 / p2)
normalized_prob
normalized_prob %>%
filter(word1 == "education") %>%
arrange(-p_together)
pmi_matrix = normalized_prob %>%
mutate(pmi = log10(p_together)) %>%
cast_sparse(word1, word2, pmi)
pmi_matrix
#remove missing data
pmi_matrix@x[is.na(pmi_matrix@x)] = 0
#run SVD
pmi_svd = irlba(pmi_matrix, 256, maxit = 500)
library(irlba)
#run SVD
pmi_svd = irlba(pmi_matrix, 256, maxit = 500)
